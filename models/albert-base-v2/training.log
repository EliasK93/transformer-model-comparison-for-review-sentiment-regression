2022-01-05 18:48:13,550 ----------------------------------------------------------------------------------------------------
2022-01-05 18:48:13,550 Model: "TextRegressor(
  (document_embeddings): TransformerDocumentEmbeddings(
    (model): AlbertModel(
      (embeddings): AlbertEmbeddings(
        (word_embeddings): Embedding(30000, 128, padding_idx=0)
        (position_embeddings): Embedding(512, 128)
        (token_type_embeddings): Embedding(2, 128)
        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0, inplace=False)
      )
      (encoder): AlbertTransformer(
        (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)
        (albert_layer_groups): ModuleList(
          (0): AlbertLayerGroup(
            (albert_layers): ModuleList(
              (0): AlbertLayer(
                (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (attention): AlbertAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (attention_dropout): Dropout(p=0, inplace=False)
                  (output_dropout): Dropout(p=0, inplace=False)
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                )
                (ffn): Linear(in_features=768, out_features=3072, bias=True)
                (ffn_output): Linear(in_features=3072, out_features=768, bias=True)
                (dropout): Dropout(p=0, inplace=False)
              )
            )
          )
        )
      )
      (pooler): Linear(in_features=768, out_features=768, bias=True)
      (pooler_activation): Tanh()
    )
  )
  (decoder): Linear(in_features=768, out_features=1, bias=True)
  (loss_function): MSELoss()
)"
2022-01-05 18:48:13,562 ----------------------------------------------------------------------------------------------------
2022-01-05 18:48:13,562 Corpus: "Corpus: 4275 train + 475 dev + 250 test sentences"
2022-01-05 18:48:13,562 ----------------------------------------------------------------------------------------------------
2022-01-05 18:48:13,562 Parameters:
2022-01-05 18:48:13,562  - learning_rate: "5e-05"
2022-01-05 18:48:13,562  - mini_batch_size: "2"
2022-01-05 18:48:13,562  - patience: "3"
2022-01-05 18:48:13,562  - anneal_factor: "0.5"
2022-01-05 18:48:13,562  - max_epochs: "10"
2022-01-05 18:48:13,562  - shuffle: "True"
2022-01-05 18:48:13,562  - train_with_dev: "False"
2022-01-05 18:48:13,562  - batch_growth_annealing: "False"
2022-01-05 18:48:13,562 ----------------------------------------------------------------------------------------------------
2022-01-05 18:48:13,563 Model training base path: "models\albert-base-v2"
2022-01-05 18:48:13,563 ----------------------------------------------------------------------------------------------------
2022-01-05 18:48:13,563 Device: cuda:0
2022-01-05 18:48:13,563 ----------------------------------------------------------------------------------------------------
2022-01-05 18:48:13,563 Embeddings storage mode: gpu
2022-01-05 18:48:13,564 ----------------------------------------------------------------------------------------------------
2022-01-05 18:48:51,241 epoch 1 - iter 213/2138 - loss 2.81328433 - samples/sec: 15.64 - lr: 0.000005
2022-01-05 18:49:19,125 epoch 1 - iter 426/2138 - loss 2.33379008 - samples/sec: 15.46 - lr: 0.000010
2022-01-05 18:49:46,372 epoch 1 - iter 639/2138 - loss 2.13898915 - samples/sec: 15.86 - lr: 0.000015
2022-01-05 18:50:14,945 epoch 1 - iter 852/2138 - loss 2.03824388 - samples/sec: 15.08 - lr: 0.000020
2022-01-05 18:50:42,950 epoch 1 - iter 1065/2138 - loss 1.85625877 - samples/sec: 15.36 - lr: 0.000025
2022-01-05 18:51:12,332 epoch 1 - iter 1278/2138 - loss 1.73192383 - samples/sec: 14.68 - lr: 0.000030
2022-01-05 18:51:41,454 epoch 1 - iter 1491/2138 - loss 1.64446134 - samples/sec: 14.81 - lr: 0.000035
2022-01-05 18:52:12,979 epoch 1 - iter 1704/2138 - loss 1.59443954 - samples/sec: 13.66 - lr: 0.000040
2022-01-05 18:52:44,970 epoch 1 - iter 1917/2138 - loss 1.57053335 - samples/sec: 13.47 - lr: 0.000045
2022-01-05 18:53:17,161 epoch 1 - iter 2130/2138 - loss 1.54700479 - samples/sec: 13.40 - lr: 0.000050
2022-01-05 18:53:18,763 ----------------------------------------------------------------------------------------------------
2022-01-05 18:53:18,763 EPOCH 1 done: loss 3309.9092 - lr 0.0000500
2022-01-05 18:53:43,060 DEV : loss 0.7740243077278137 - f1-score (micro avg)  0.7631
2022-01-05 18:53:44,554 BAD EPOCHS (no improvement): 4
2022-01-05 18:53:44,555 ----------------------------------------------------------------------------------------------------
2022-01-05 18:54:24,832 epoch 2 - iter 213/2138 - loss 1.73658783 - samples/sec: 15.09 - lr: 0.000049
2022-01-05 18:54:52,014 epoch 2 - iter 426/2138 - loss 1.40058659 - samples/sec: 15.84 - lr: 0.000049
2022-01-05 18:55:22,884 epoch 2 - iter 639/2138 - loss 1.29141966 - samples/sec: 13.98 - lr: 0.000048
2022-01-05 18:55:54,474 epoch 2 - iter 852/2138 - loss 1.18758895 - samples/sec: 13.62 - lr: 0.000048
2022-01-05 18:56:26,344 epoch 2 - iter 1065/2138 - loss 1.21264921 - samples/sec: 13.54 - lr: 0.000047
2022-01-05 18:56:56,107 epoch 2 - iter 1278/2138 - loss 1.31519003 - samples/sec: 14.48 - lr: 0.000047
2022-01-05 18:57:26,358 epoch 2 - iter 1491/2138 - loss 1.36807858 - samples/sec: 14.22 - lr: 0.000046
2022-01-05 18:57:58,561 epoch 2 - iter 1704/2138 - loss 1.31186043 - samples/sec: 13.39 - lr: 0.000046
2022-01-05 18:58:29,000 epoch 2 - iter 1917/2138 - loss 1.26113823 - samples/sec: 14.13 - lr: 0.000045
2022-01-05 18:58:58,512 epoch 2 - iter 2130/2138 - loss 1.22874031 - samples/sec: 14.60 - lr: 0.000044
2022-01-05 18:58:59,566 ----------------------------------------------------------------------------------------------------
2022-01-05 18:58:59,566 EPOCH 2 done: loss 2623.2983 - lr 0.0000444
2022-01-05 18:59:23,923 DEV : loss 0.7666823863983154 - f1-score (micro avg)  0.7458
2022-01-05 18:59:25,398 BAD EPOCHS (no improvement): 4
2022-01-05 18:59:25,399 ----------------------------------------------------------------------------------------------------
2022-01-05 19:00:05,015 epoch 3 - iter 213/2138 - loss 0.97678216 - samples/sec: 14.98 - lr: 0.000044
2022-01-05 19:00:34,450 epoch 3 - iter 426/2138 - loss 0.86977710 - samples/sec: 14.64 - lr: 0.000043
2022-01-05 19:01:05,065 epoch 3 - iter 639/2138 - loss 0.82154377 - samples/sec: 14.07 - lr: 0.000043
2022-01-05 19:01:35,724 epoch 3 - iter 852/2138 - loss 0.85586876 - samples/sec: 14.05 - lr: 0.000042
2022-01-05 19:02:07,601 epoch 3 - iter 1065/2138 - loss 0.83466819 - samples/sec: 13.51 - lr: 0.000042
2022-01-05 19:02:41,351 epoch 3 - iter 1278/2138 - loss 0.81850409 - samples/sec: 12.77 - lr: 0.000041
2022-01-05 19:03:13,158 epoch 3 - iter 1491/2138 - loss 0.81060757 - samples/sec: 13.52 - lr: 0.000041
2022-01-05 19:03:43,165 epoch 3 - iter 1704/2138 - loss 0.81084259 - samples/sec: 14.36 - lr: 0.000040
2022-01-05 19:04:13,024 epoch 3 - iter 1917/2138 - loss 0.80895670 - samples/sec: 14.42 - lr: 0.000039
2022-01-05 19:04:43,244 epoch 3 - iter 2130/2138 - loss 0.79317696 - samples/sec: 14.25 - lr: 0.000039
2022-01-05 19:04:44,470 ----------------------------------------------------------------------------------------------------
2022-01-05 19:04:44,470 EPOCH 3 done: loss 1696.9344 - lr 0.0000389
2022-01-05 19:05:08,294 DEV : loss 0.3601979911327362 - f1-score (micro avg)  0.8211
2022-01-05 19:05:09,740 BAD EPOCHS (no improvement): 4
2022-01-05 19:05:09,740 ----------------------------------------------------------------------------------------------------
2022-01-05 19:05:49,426 epoch 4 - iter 213/2138 - loss 0.53309866 - samples/sec: 15.02 - lr: 0.000038
2022-01-05 19:06:17,458 epoch 4 - iter 426/2138 - loss 0.55683913 - samples/sec: 15.38 - lr: 0.000038
2022-01-05 19:06:47,761 epoch 4 - iter 639/2138 - loss 0.60421478 - samples/sec: 14.22 - lr: 0.000037
2022-01-05 19:07:18,342 epoch 4 - iter 852/2138 - loss 0.59171749 - samples/sec: 14.09 - lr: 0.000037
2022-01-05 19:07:48,064 epoch 4 - iter 1065/2138 - loss 0.58448040 - samples/sec: 14.50 - lr: 0.000036
2022-01-05 19:08:17,839 epoch 4 - iter 1278/2138 - loss 0.58006825 - samples/sec: 14.44 - lr: 0.000036
2022-01-05 19:08:50,653 epoch 4 - iter 1491/2138 - loss 0.58010013 - samples/sec: 13.13 - lr: 0.000035
2022-01-05 19:09:21,290 epoch 4 - iter 1704/2138 - loss 0.58384777 - samples/sec: 14.07 - lr: 0.000034
2022-01-05 19:09:52,397 epoch 4 - iter 1917/2138 - loss 0.58723415 - samples/sec: 13.85 - lr: 0.000034
2022-01-05 19:10:24,093 epoch 4 - iter 2130/2138 - loss 0.58060873 - samples/sec: 13.59 - lr: 0.000033
2022-01-05 19:10:26,393 ----------------------------------------------------------------------------------------------------
2022-01-05 19:10:26,394 EPOCH 4 done: loss 1240.2088 - lr 0.0000333
2022-01-05 19:10:50,442 DEV : loss 0.3082665503025055 - f1-score (micro avg)  0.8428
2022-01-05 19:10:51,927 BAD EPOCHS (no improvement): 4
2022-01-05 19:10:51,928 ----------------------------------------------------------------------------------------------------
2022-01-05 19:11:30,414 epoch 5 - iter 213/2138 - loss 0.42570170 - samples/sec: 15.54 - lr: 0.000033
2022-01-05 19:11:57,173 epoch 5 - iter 426/2138 - loss 0.43833683 - samples/sec: 16.11 - lr: 0.000032
2022-01-05 19:12:26,038 epoch 5 - iter 639/2138 - loss 0.39896818 - samples/sec: 14.92 - lr: 0.000032
2022-01-05 19:12:55,802 epoch 5 - iter 852/2138 - loss 0.40794472 - samples/sec: 14.47 - lr: 0.000031
2022-01-05 19:13:26,134 epoch 5 - iter 1065/2138 - loss 0.40051845 - samples/sec: 14.20 - lr: 0.000031
2022-01-05 19:13:56,887 epoch 5 - iter 1278/2138 - loss 0.40337406 - samples/sec: 14.01 - lr: 0.000030
2022-01-05 19:14:28,454 epoch 5 - iter 1491/2138 - loss 0.40019243 - samples/sec: 13.64 - lr: 0.000029
2022-01-05 19:15:00,041 epoch 5 - iter 1704/2138 - loss 0.38645047 - samples/sec: 13.64 - lr: 0.000029
2022-01-05 19:15:29,969 epoch 5 - iter 1917/2138 - loss 0.39029302 - samples/sec: 14.39 - lr: 0.000028
2022-01-05 19:16:02,293 epoch 5 - iter 2130/2138 - loss 0.38209715 - samples/sec: 13.34 - lr: 0.000028
2022-01-05 19:16:03,971 ----------------------------------------------------------------------------------------------------
2022-01-05 19:16:03,971 EPOCH 5 done: loss 816.9671 - lr 0.0000278
2022-01-05 19:16:27,654 DEV : loss 0.2933017611503601 - f1-score (micro avg)  0.8519
2022-01-05 19:16:29,217 BAD EPOCHS (no improvement): 4
2022-01-05 19:16:29,218 ----------------------------------------------------------------------------------------------------
2022-01-05 19:17:06,588 epoch 6 - iter 213/2138 - loss 0.25479059 - samples/sec: 16.34 - lr: 0.000027
2022-01-05 19:17:36,741 epoch 6 - iter 426/2138 - loss 0.26255395 - samples/sec: 14.31 - lr: 0.000027
2022-01-05 19:18:08,476 epoch 6 - iter 639/2138 - loss 0.25254547 - samples/sec: 13.57 - lr: 0.000026
2022-01-05 19:18:38,761 epoch 6 - iter 852/2138 - loss 0.23622705 - samples/sec: 14.23 - lr: 0.000026
2022-01-05 19:19:07,347 epoch 6 - iter 1065/2138 - loss 0.24072146 - samples/sec: 15.08 - lr: 0.000025
2022-01-05 19:19:39,313 epoch 6 - iter 1278/2138 - loss 0.25117788 - samples/sec: 13.47 - lr: 0.000024
2022-01-05 19:20:08,049 epoch 6 - iter 1491/2138 - loss 0.24988122 - samples/sec: 15.00 - lr: 0.000024
2022-01-05 19:20:40,543 epoch 6 - iter 1704/2138 - loss 0.24901041 - samples/sec: 13.24 - lr: 0.000023
2022-01-05 19:21:09,342 epoch 6 - iter 1917/2138 - loss 0.24985352 - samples/sec: 14.94 - lr: 0.000023
2022-01-05 19:21:39,621 epoch 6 - iter 2130/2138 - loss 0.25226186 - samples/sec: 14.22 - lr: 0.000022
2022-01-05 19:21:40,746 ----------------------------------------------------------------------------------------------------
2022-01-05 19:21:40,746 EPOCH 6 done: loss 538.7581 - lr 0.0000222
2022-01-05 19:22:04,513 DEV : loss 0.3125239312648773 - f1-score (micro avg)  0.854
2022-01-05 19:22:05,989 BAD EPOCHS (no improvement): 4
2022-01-05 19:22:06,000 ----------------------------------------------------------------------------------------------------
2022-01-05 19:22:45,341 epoch 7 - iter 213/2138 - loss 0.13816010 - samples/sec: 15.24 - lr: 0.000022
2022-01-05 19:23:14,539 epoch 7 - iter 426/2138 - loss 0.15022205 - samples/sec: 14.76 - lr: 0.000021
2022-01-05 19:23:43,711 epoch 7 - iter 639/2138 - loss 0.15737287 - samples/sec: 14.78 - lr: 0.000021
2022-01-05 19:24:13,501 epoch 7 - iter 852/2138 - loss 0.16359333 - samples/sec: 14.47 - lr: 0.000020
2022-01-05 19:24:43,956 epoch 7 - iter 1065/2138 - loss 0.16017391 - samples/sec: 14.14 - lr: 0.000019
2022-01-05 19:25:15,465 epoch 7 - iter 1278/2138 - loss 0.15803783 - samples/sec: 13.67 - lr: 0.000019
2022-01-05 19:25:44,885 epoch 7 - iter 1491/2138 - loss 0.15915286 - samples/sec: 14.65 - lr: 0.000018
2022-01-05 19:26:14,806 epoch 7 - iter 1704/2138 - loss 0.15816962 - samples/sec: 14.40 - lr: 0.000018
2022-01-05 19:26:45,618 epoch 7 - iter 1917/2138 - loss 0.15679547 - samples/sec: 13.97 - lr: 0.000017
2022-01-05 19:27:15,882 epoch 7 - iter 2130/2138 - loss 0.15612677 - samples/sec: 14.21 - lr: 0.000017
2022-01-05 19:27:17,315 ----------------------------------------------------------------------------------------------------
2022-01-05 19:27:17,315 EPOCH 7 done: loss 333.8552 - lr 0.0000167
2022-01-05 19:27:41,078 DEV : loss 0.25874435901641846 - f1-score (micro avg)  0.8705
2022-01-05 19:27:42,576 BAD EPOCHS (no improvement): 4
2022-01-05 19:27:42,577 ----------------------------------------------------------------------------------------------------
2022-01-05 19:28:20,158 epoch 8 - iter 213/2138 - loss 0.12174490 - samples/sec: 16.26 - lr: 0.000016
2022-01-05 19:28:47,285 epoch 8 - iter 426/2138 - loss 0.10289668 - samples/sec: 15.87 - lr: 0.000016
2022-01-05 19:29:18,042 epoch 8 - iter 639/2138 - loss 0.10467933 - samples/sec: 14.03 - lr: 0.000015
2022-01-05 19:29:48,980 epoch 8 - iter 852/2138 - loss 0.10409394 - samples/sec: 13.92 - lr: 0.000014
2022-01-05 19:30:18,365 epoch 8 - iter 1065/2138 - loss 0.09895167 - samples/sec: 14.66 - lr: 0.000014
2022-01-05 19:30:50,425 epoch 8 - iter 1278/2138 - loss 0.09527772 - samples/sec: 13.43 - lr: 0.000013
2022-01-05 19:31:20,861 epoch 8 - iter 1491/2138 - loss 0.09875552 - samples/sec: 14.15 - lr: 0.000013
2022-01-05 19:31:53,704 epoch 8 - iter 1704/2138 - loss 0.09698792 - samples/sec: 13.11 - lr: 0.000012
2022-01-05 19:32:22,710 epoch 8 - iter 1917/2138 - loss 0.09865702 - samples/sec: 14.86 - lr: 0.000012
2022-01-05 19:32:53,892 epoch 8 - iter 2130/2138 - loss 0.09611503 - samples/sec: 13.81 - lr: 0.000011
2022-01-05 19:32:55,280 ----------------------------------------------------------------------------------------------------
2022-01-05 19:32:55,281 EPOCH 8 done: loss 205.2947 - lr 0.0000111
2022-01-05 19:33:19,063 DEV : loss 0.26496508717536926 - f1-score (micro avg)  0.8667
2022-01-05 19:33:20,538 BAD EPOCHS (no improvement): 4
2022-01-05 19:33:20,538 ----------------------------------------------------------------------------------------------------
2022-01-05 19:33:57,895 epoch 9 - iter 213/2138 - loss 0.07252567 - samples/sec: 16.38 - lr: 0.000011
2022-01-05 19:34:25,140 epoch 9 - iter 426/2138 - loss 0.06542782 - samples/sec: 15.83 - lr: 0.000010
2022-01-05 19:34:53,770 epoch 9 - iter 639/2138 - loss 0.06692428 - samples/sec: 15.05 - lr: 0.000009
2022-01-05 19:35:25,090 epoch 9 - iter 852/2138 - loss 0.05835645 - samples/sec: 13.75 - lr: 0.000009
2022-01-05 19:35:55,665 epoch 9 - iter 1065/2138 - loss 0.06058625 - samples/sec: 14.11 - lr: 0.000008
2022-01-05 19:36:25,520 epoch 9 - iter 1278/2138 - loss 0.05726437 - samples/sec: 14.41 - lr: 0.000008
2022-01-05 19:36:54,891 epoch 9 - iter 1491/2138 - loss 0.05570002 - samples/sec: 14.67 - lr: 0.000007
2022-01-05 19:37:23,268 epoch 9 - iter 1704/2138 - loss 0.05549018 - samples/sec: 15.18 - lr: 0.000007
2022-01-05 19:37:54,837 epoch 9 - iter 1917/2138 - loss 0.05619027 - samples/sec: 13.66 - lr: 0.000006
2022-01-05 19:38:25,526 epoch 9 - iter 2130/2138 - loss 0.05382317 - samples/sec: 14.04 - lr: 0.000006
2022-01-05 19:38:26,792 ----------------------------------------------------------------------------------------------------
2022-01-05 19:38:26,793 EPOCH 9 done: loss 114.6510 - lr 0.0000056
2022-01-05 19:38:51,232 DEV : loss 0.277094304561615 - f1-score (micro avg)  0.8639
2022-01-05 19:38:52,726 BAD EPOCHS (no improvement): 4
2022-01-05 19:38:52,726 ----------------------------------------------------------------------------------------------------
2022-01-05 19:39:29,638 epoch 10 - iter 213/2138 - loss 0.01553064 - samples/sec: 16.54 - lr: 0.000005
2022-01-05 19:39:57,887 epoch 10 - iter 426/2138 - loss 0.03141318 - samples/sec: 15.28 - lr: 0.000004
2022-01-05 19:40:26,559 epoch 10 - iter 639/2138 - loss 0.02723193 - samples/sec: 15.00 - lr: 0.000004
2022-01-05 19:40:52,362 epoch 10 - iter 852/2138 - loss 0.03088416 - samples/sec: 16.66 - lr: 0.000003
2022-01-05 19:41:18,952 epoch 10 - iter 1065/2138 - loss 0.02872279 - samples/sec: 16.22 - lr: 0.000003
2022-01-05 19:41:48,826 epoch 10 - iter 1278/2138 - loss 0.03160945 - samples/sec: 14.41 - lr: 0.000002
2022-01-05 19:42:17,515 epoch 10 - iter 1491/2138 - loss 0.03318044 - samples/sec: 15.00 - lr: 0.000002
2022-01-05 19:42:44,773 epoch 10 - iter 1704/2138 - loss 0.03404730 - samples/sec: 15.79 - lr: 0.000001
2022-01-05 19:43:13,139 epoch 10 - iter 1917/2138 - loss 0.03270892 - samples/sec: 15.16 - lr: 0.000001
2022-01-05 19:43:42,998 epoch 10 - iter 2130/2138 - loss 0.03248901 - samples/sec: 14.47 - lr: 0.000000
2022-01-05 19:43:44,055 ----------------------------------------------------------------------------------------------------
2022-01-05 19:43:44,055 EPOCH 10 done: loss 69.2021 - lr 0.0000000
2022-01-05 19:44:06,761 DEV : loss 0.2701475918292999 - f1-score (micro avg)  0.866
2022-01-05 19:44:08,229 BAD EPOCHS (no improvement): 4
2022-01-05 19:44:08,326 ----------------------------------------------------------------------------------------------------
2022-01-05 19:44:08,326 Testing using last state of model ...
2022-01-05 19:44:24,900 0.5293086817219169	0.8559422054145616	0.8642052037670703
2022-01-05 19:44:24,900 AVG: mse: 0.5293 - mae: 0.4323 - pearson: 0.8642 - spearman: 0.8559
2022-01-05 19:44:24,900 ----------------------------------------------------------------------------------------------------
